---
title: "FML_Assignment_4"
author: "Rupesh_Suragani"
date: "2023-11-12"
output: html_document
---
#Directions of the problem

An equities analyst is studying the pharmaceutical industry and would like your help in exploring and understanding the financial data collected by her firm. Her main objective is to understand the structure of the pharmaceutical industry using some basic financial measures. Financial data gathered on 21 firms in the pharmaceutical industry are available in the file Pharmaceuticals.csv

For each firm, the following variables are recorded:  

1. Market capitalization (in billions of dollars)
2. Beta
3. Price/earnings ratio
4. Return on equity
5. Return on assets
6. Asset turnover
7. Leverage
8. Estimated revenue growth
9. Net profit margin
10. Median recommendation (across major brokerages)
11. Location of firmâ€™s headquarters
12. Stock exchange on which the firm is listed

Use cluster analysis to explore and analyze the given dataset as follows: 


```{r}
library(tidyverse)
library(factoextra)
library(ISLR)
library(cluster)
library(dbscan)
library(fpc)
library(ggplot2)
```


```{r}
#Loading the csv data
pharmacy <- read.csv("C:\\Users\\rupes\\OneDrive\\Desktop\\Kent State University\\FML\\Assignment 4\\Pharmaceuticals.csv")
head(pharmacy)

pharmacy <- na.omit(pharmacy)

#Dimensions of the csv data
dim(pharmacy)

#Printing all the variable names
t(t(names(pharmacy)))
```



#a. Use only the numerical variables (1 to 9) to cluster the 21 firms. Justify the various choices made in conducting the cluster analysis, such as weights for different variables, the specific clustering algorithm(s) used, the number of clusters formed, and so on.

A). From the given csv data (Pharmaceuticals.csv) the numerical variables are Market capitalization, Beta, Price/earnings ratio, Return on equity, Return on assets, Asset turnover, Leverage, Estimated revenue growth, and Net profit margin

Using Only the numerical variables (3 to 11 variables in the data) to cluster the 21 firms.
```{r}
set.seed(123)

#Selecting the numerical variables 1 to 9

#In the Pharmacy data the numerical variables exist from column 3 to column 11.
row.names(pharmacy) <- pharmacy[,1]
num_pharma_data <- pharmacy[ , c(3 : 11)]
head(num_pharma_data)

#Dimensions
dim(num_pharma_data)

#Numeric variables
t(t(names(num_pharma_data)))
```

#Normalizing the Numerical Pharma data of 21 firms using scale function
```{r}
#Normalizing the numerical data (z-score)
Scale_pharma <- scale(num_pharma_data)
Scale_pharma
```


```{r}
#Virtual representation of normalized distance between the observations
distance <- get_dist(Scale_pharma) 
fviz_dist(distance) #This shows the distance between the observations
```

choosing different clustering algorithms

1. K_means Clustering:

One of the key decisions in cluster analysis is to determine the number of clusters and the optimal number of clusters will vary depending on the dataset. For getting out the optimal number of clusters to be formed, Elbow method can be implemented.

```{r}
#Graphical representation of optimal number of clusters using Elbow method
fviz_nbclust(Scale_pharma, kmeans, method = "wss") + labs(subtitle = "Elbow Method of kmeans")
```
From the above graph, the optimal number of clusters can be taken as 2 because in the graph of elbow method the elbow bent is seen at point 2. Hence K shall be taken as 2.

#Taking k =2 for calculating kmeans.
```{r}
set.seed(159)
k = 2
elbow_cluster <- kmeans(Scale_pharma, centers = k, nstart = 21)
elbow_cluster

#Finding the Centroids
elbow_cluster$centers

#Visualization of cluster
fviz_cluster(elbow_cluster, Scale_pharma) + ggtitle("k = 2")
```

```{r}
#Finding which firm belongs to which cluster
elbow_cluster$cluster
```
```{r}
#cluster size
elbow_cluster$size
```


Similar to Elbow method we can use Average silhouette method to find the best k(optimal number of clusters)
```{r}
fviz_nbclust(Scale_pharma, kmeans, method = "silhouette") + labs(subtitle = "cluster using Silhouette Method ")
```

On analyzing silhouette method the optimal number of clusters can be taken as 5.

```{r}
set.seed(159)
k = 5
sil_cluster <- kmeans(Scale_pharma, centers = k, nstart = 21)
sil_cluster
```

```{r}
#Finding the Centroids
sil_cluster$centers
```

```{r}
#Finding which firm belongs to which cluster
sil_cluster$cluster
```

```{r}
#cluster size
sil_cluster$size
```

```{r}
#Visualization of cluster
fviz_cluster(sil_cluster, Scale_pharma) + ggtitle("k = 5")
```

from the output of this kmeans clustering with k value of 5. we can see that 4 Firms comes under first cluster, 2 firms under second cluster, 3 companies under third cluster, 8 firms under fourth cluster and the remaining comes under fifth cluster, by taking all the numerical variables as these all are the financial measures are to be considered to know the equity, as equity depends on Market capital, net profit, return on assets, asset turnover, etc. And in this we can see the points are much nearer to the centroids. And this cluster might be the best. lets consider the remaining clusters


#Kmeans cluster analysis for fitting the data with 5 clusters
```{r}
fit_data <- kmeans(Scale_pharma, 5)
```

#Calculating mean of all quantitative variables in each cluster
```{r}
aggregate(Scale_pharma, by = list(fit_data$cluster), FUN = mean)
```

```{r}
clusplot(Scale_pharma, fit_data$cluster, color = TRUE, shade = TRUE, labels = 2, lines = 0)
```


#DBSCAN clustering

Determining the Optimal 'eps' value
```{r}
dbscan::kNNdistplot(num_pharma_data, k = 4)
```

KNN-dist plot is used to determine the optimal value of radius for DBSCAN clustering, we need to take the radius from where the curve was bent. From the above Plot, we can see that the curve was bent at distance between 20 and 40. so, consider the radius or EPS value as 30 at minimum points of 4.

```{r}
dbcluster <- dbscan::dbscan(num_pharma_data, eps = 30, minPts = 4)
dbcluster
```

```{r}
#Printing out which point belongs to which cluster
dbcluster$cluster
```
```{r}
# Visualization of clusters
fviz_cluster(dbcluster, num_pharma_data) + ggtitle("DBSCAN Plot")
```

From the output and Plot of the DBSCAN clustering with the radius of 30 and minimum points of 4, we can see that 2 clusters are formed, one cluster with 8 points and the second cluster with 7 points and remaining six points as outliers. we can see the outliers from the plot. a good cluster should have minimum number of outliers, so we can say that this was not a good clustering process.

#Hierarchical Clustering
```{r}
#Dissimilarity matrix
d <- dist(num_pharma_data, method = "euclidean")

#Hierarchical clustering using complete Linkage
hc_complete <- agnes(num_pharma_data, method = "complete")

#plot the obtained dendogram
pltree(hc_complete, cex = 0.75, hang = -1, main = "Dendograms of agnes")
rect.hclust(hc_complete, k = 4, border = 1:4)
```
in hierarchical clustering, 4 clusters are formed. from the dendrogram we can say that
first cluster with size 8
second cluster with size 2
third cluster with size 7
fourth cluster with size 4
but here in this clustering, one cluster have many points and the other have too less, so this might not be a good one to do clustering of all the companies.

```{r}
heatmap(as.matrix(Scale_pharma), Colv = NA, hclustfun = hclust, 
        col=rev(paste("gray",1:99,sep="")))
```

Out of all these clusters I have found that Kmeans clustering with no.of clusters as 5 produce better clusters.
*********

2. Interpret the clusters with respect to the numerical variables used in forming the clusters. Is there a pattern in the clusters with respect to the numerical variables (10 to 12)?
```{r}
# creating a table with clusters
cluster1 <- pharmacy[,c(2:11)]  %>% 
                   mutate(cluster = sil_cluster$cluster) %>% arrange(cluster, ascending = T)

# dataset with clusters
cluster1
cluster1[,c(1,11)]
```
Agglomerative coefficient measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure)
```{r}
library(cluster)

#Computing with agnes and with different linkage methods
hc_single <- agnes(num_pharma_data, method = "single")
hc_complete <- agnes(num_pharma_data, method = "complete")
hc_average <- agnes(num_pharma_data, method = "average")

#comparing agglomerative coefficients
print(hc_single$ac)
```

```{r}
print(hc_complete$ac)
```

```{r}
print(hc_average$ac)
```

Here, hc_complete is the best linkage method
```{r}
pltree(hc_complete, cex = 0.6, hang = -1, main = "Dendograms of agnes")
rect.hclust(hc_complete, k = 4, border = 1:4)
```

From the above Dendogram, the clustering analysis is as follows:

Cluster 1 (ABT, AZN, LLY, NVS, AVE, SGP, BMY, WYE) : These are the Large firms with high market capitalization, beta, and price/earnings ratios. These firms are also relatively leveraged.

Cluster 2(AGN, PHA): These are the Medium-sized firms with moderate market capitalization, beta, and price/earnings ratios. These firms are also less leveraged.

Cluster 3 (AHM, IVX, CHTT, BAY, ELN, MRX, WPI) : These are Small- to medium-sized firms with high market capitalization and moderate beta and price/earnings ratios. These firms are also less leveraged.

Cluster 4 (GSK, MRK, JNJ, PFE) : These are also Small- to medium-sized companies with moderate market capitalization and high beta and price/earnings ratios. But these companies are more leveraged.


The R function diana provided by the cluster package allows us to perform divisive hierarchical clustering. Diana works similar to agnes; however, there is no method to provide.
```{r}
#compute divisive hierarchical clustering
hc_diana <- diana(num_pharma_data)

#Divise coefficient; amount of clustering structure found
hc_diana$dc
```
```{r}
#Plot dendrogram
pltree(hc_diana, cex = 0.6, hang = -1, main = "Dendogram of diana")
```

Interpret the clusters with respect to the numerical variables used in forming the clusters. Is there a pattern in the clusters with respect to the numerical variables (10 to 12)?

Interpretation of the above clusters: